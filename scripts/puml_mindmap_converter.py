"""
ä¸»è¦å°†plantumlçš„mindmapå†™æ³•è½¬ä¸ºvegaå¯ç”¨çš„jsonæ–‡ä»¶
"""
import sys
import os
import re
import json


def converter(puml_path: str):
    """
    ä¼ å…¥pumlæ–‡ä»¶è·¯å¾„è¿›è¡Œè§£æè½¬åŒ–
    1. æ ‡é¢˜éƒ½æ˜¯ä»¥*å¼€å¤´, ä¸”ä¸€ä¸ª*çš„éƒ½æ˜¯æ ¹èŠ‚ç‚¹
    2. çˆ¶çº§èŠ‚ç‚¹åªä¼šæ¯”å­çº§èŠ‚ç‚¹å°‘ä¸€ä¸ª*ï¼Œå¦‚æœå½“å‰èŠ‚ç‚¹æ¯”ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å°‘äºè¶…è¿‡ä¸€ä¸ª*ï¼Œpumlå°±æ— æ³•é€šè¿‡
    3. å¦‚æœä¸‹ä¸€ä¸ªèŠ‚ç‚¹æ¯”ä¸Šä¸€ä¸ªèŠ‚ç‚¹å°‘*ï¼Œå°±å»å¯¹åº”åˆ—è¡¨é‡Œé¢æ‰¾æœ€åä¸€ä¸ª
    :param puml_path:
    :return:
    """
    print(f"å¼€å§‹å¤„ç†{puml_path}...")
    levels = {}
    json_results = []
    with open(puml_path, 'r') as f:
        notes = extract_notes(f.read())

    with open(puml_path, 'r') as f:
        lines = [line for line in f.readlines()]
        title_index = 1
        for index, line in enumerate(lines):
            # æ ‡é¢˜çš„*åé¢åªä¼šå‡ºç°ä¸‰ç§æƒ…å†µï¼šç©ºæ ¼ã€:ã€[
            if line.startswith('*'):
                stars, name, color, links = extract_stars_name_links_color(line)
                # å­˜æ”¾èŠ‚ç‚¹ä¿¡æ¯ã€èŠ‚ç‚¹idã€èŠ‚ç‚¹å¤šå°‘å­èŠ‚ç‚¹
                levels[stars] = [line, title_index, 0]
                parent = levels.get(stars[:-1])
                node = {
                    "id": title_index,
                    "layers": len(stars),
                    "name": name,
                    # "size": len(name)
                    # "link": 'https://www.google.com'
                }
                title_index += 1
                if parent:
                    node["parent"] = parent[1]
                    parent[2] = parent[2] + 1
                if links:
                    # å¦‚æœæ˜¯æœ‰é“¾æ¥ï¼Œå°±å˜æˆå­èŠ‚ç‚¹
                    link_count = 1
                    for link_name, link_detail in links.items():
                        link, title_note = link_detail
                        if link_count == 1:
                            node['link'] = link
                        if link_count > 1:  # å¤šäºä¸€ä¸ªé“¾æ¥æ‰ä½œä¸ºå­èŠ‚ç‚¹
                            child_node = {
                                "id": title_index,
                                "name": f"é“¾æ¥{link_count}: {link_name}",
                                "link": link,
                                "parent": node['id'],
                                "note": f'æ¥è‡ª{node["name"]}çš„é“¾æ¥'
                            }
                            title_index += 1
                            json_results.append(child_node)
                            link_count += 1
                if color:
                    node["color"] = '#' + color
                if index < len(lines) and lines[index + 1].startswith('<code>'):
                    note = notes.pop(0)
                    node['note'] = f"{title_note}\n{note}" if title_note else note
                json_results.append(node)
    json_results = add_child_count(json_results)
    json_results = add_node_count(json_results)
    json_results = add_tool_tip(json_results)
    return json_results


def add_child_count(parse_results: list[dict]):
    """
    æ·»åŠ å­èŠ‚ç‚¹æ•°é‡, æ ¹æ®å­èŠ‚ç‚¹æ•°é‡æ§åˆ¶æ ‡é¢˜æ¢è¡Œ
    :param parse_results:
    :return:
    """
    children_count = {}
    for node in parse_results:
        if node.get('parent'):  # æ ¹èŠ‚ç‚¹å°±ä¸å¤„ç†
            children_count[node['parent']] = children_count.get(node['parent'], 0) + 1
    # å†åŠ ä¸Šå­èŠ‚ç‚¹æ•°é‡
    for node in parse_results:
        node['child_count'] = children_count.get(node['id'], 0)
        node['name'] = get_wrap_name(node['name'], node['child_count'])
    return parse_results


def add_node_count(parse_results: list[dict]):
    """
    æ ¹æ®å­èŠ‚ç‚¹æ•°é‡child_count+1ä½œä¸ºçˆ¶èŠ‚ç‚¹åä¸‹èŠ‚ç‚¹çš„æ•°é‡node_count
    æŒ‰å±‚æ•°ä»å¤–åˆ°å†…ç¼©å°
    :param parse_results:
    :return:
    """
    layers_list = {}
    max_layer = 1
    for node in parse_results:
        layer = node['layers']
        if not layers_list.get(layer):
            layers_list[layer] = []
        layers_list[layer].append(node)
        if layer > max_layer:
            max_layer = layer
    id_dict = {node['id']: node for node in parse_results}
    while max_layer > 0:
        layer_nodes = layers_list[max_layer]
        for node in layer_nodes:
            parent = id_dict.get(node.get('parent', None))
            if parent:
                # parent['node_count'] = parent.get('node_count', 1) + node.get('node_count', 1)
                parent['node_count'] = parent.get('node_count', 0) + node.get('node_count', 1)
            if node.get('child_count') == 0:
                node['node_count'] = 1
        max_layer -= 1
    parsed_results = []
    for layer, nodes in layers_list.items():
        parsed_results.extend(nodes)
    # æœ€åç»Ÿä¸€è®¡ç®—æ‰€å è§’åº¦
    # root = layers_list[1][0]
    # total_node_count = root['node_count']
    # node_angle = float('%.4f' % (360 / total_node_count))
    # for node in parsed_results:
    #     node['node_angle'] = node['node_count'] * node_angle
    return parsed_results


def add_tool_tip(parse_results: list[dict]):
    optional_fileds = ['note', 'link']
    for node in parse_results:
        node['tool_tip'] = {
            'title': node['name'],
        }
        for field in optional_fileds:
            value = node.get(field)
            if value:
                node['tool_tip'][field] = value
    return parse_results


def write_bubble_json(parse_results: list[dict], target_directory: str):
    filename = f"{re.split('[/|.]', puml_path)[-2]}_bubble.json"
    # file_path = '../src/overview/vega/'
    amount_start = 0.91
    bubble_content = []
    for item in parse_results:
        node = {
            "category": item['name'],
            "amount": float('%.2f' % (amount_start - 0.03 * item['layers']))
        }
        if item.get('link'):
            node['link'] = item['link']
        if item.get('note'):
            node['note'] = item['note']
        bubble_content.append(node)
    with open(f"{target_directory}{filename}", 'w') as f:
        f.write(json.dumps(bubble_content))


def write_knowledge_graph_json(parse_results: list[dict], target_directory: str):
    filename = f"{re.split('[/|.]', puml_path)[-2]}_knowledge_graph.json"
    # file_path = '../src/overview/vega/'
    # knowledge_graph_nodes = parse_results
    knowledge_graph_links = []
    knowledge_graph_nodes = []
    for node in parse_results:
        if node.get('parent'):
            link = {'source': node['id'], 'target': node['parent'], 'value': 1}
            knowledge_graph_links.append(link)
        node['index'] = node['id']
        knowledge_graph_nodes.append(node)
    knowledge_graph = {'nodes': knowledge_graph_nodes, 'links': knowledge_graph_links}
    with open(f"{target_directory}{filename}", 'w') as f:
        f.write(json.dumps(knowledge_graph))


def write_tree_json(parse_results: list[dict], target_directory: str):
    filename = f"{re.split('[/|.]', puml_path)[-2]}"
    # file_path = '../src/overview/vega/'
    with open(f"{target_directory}{filename}.json", 'w') as f:
        f.write(json.dumps(parse_results))
    with open("../src/layer5_source_code_anatomy/substrate_anatomy/vega/radial_tree_template.vg.json", "r") as f:
        template = f.readlines()
    for index, line in enumerate(template):
        if 'url' in line:
            raw_data_url = re.findall('"(.*?)"', line)[1]
            template[index] = template[index].replace(raw_data_url, f'vega/{filename}.json')
            print(line)
    with open(f"{target_directory}{filename}_radial_tree.vg.json", "w") as f:
        f.writelines(template)


def extract_stars_name_links_color(line=''):
    color = None
    links = extract_links(line)
    link_dict = {}
    for index, link_detail in enumerate(links):
        href, raw_title, url_title = link_detail['link'], link_detail['raw_title'], link_detail['url_title']
        title_choices = [item for item in [raw_title, url_title, link_detail['real_title']] if item]
        short_title = min(title_choices, key=len)
        # é™¤äº†ç¬¬ä¸€ä¸ªé“¾æ¥ï¼Œå…¶ä»–éƒ½ä½œä¸ºå­é“¾æ¥
        if index == 0:
            line = line.replace(f"[[{href} {raw_title}]]", f' {short_title}')
        else:
            line = line.replace(f"[[{href} {short_title}]]", "")
        link_dict[short_title] = [href, link_detail['title_note']]
    stars = re.split('[ :\[]', line)[0]
    name = line[len(stars):]
    if name.startswith('[#'):  # å¦‚æœæœ‰é¢œè‰²
        color = re.findall('\[#(.*?)\]', name)[0]
        name = name.split(']')[1]
    if name.startswith(':'):  # å¦‚æœæœ‰æ³¨é‡Š
        name = name[1:]
    return stars, name, color, link_dict


def get_wrap_name(name, child_count):
    """
    æ ¹æ®å­èŠ‚ç‚¹ä¸ªæ•°æ¥ç¡®å®šæ¢è¡Œ,é¿å…æ–‡å­—é‡å 
    ä¸€èˆ¬æ¥è¯´ï¼Œçˆ¶èŠ‚ç‚¹è¡Œæ•° = å­èŠ‚ç‚¹ä¸ªæ•° - 1
    :param name:
    :param child_count:
    :return:
    """
    # ç»Ÿä¸€æ·»åŠ æ¢è¡Œç¬¦
    name = name.strip().replace('  ', ' ')
    wrap_name_list = [char for char in name]
    # space_count = 0
    wrap_count = 0
    # symbols = ['/', '-']
    for index, char in enumerate(wrap_name_list):
        # if char == ' ':
        #    space_count += 1
        # if space_count == 2:
        #    if wrap_count < child_count:
        #        wrap_name_list[index] = '\n'
        #        wrap_count += 1
        #    space_count = 0
        # if char in symbols:
        #    wrap_name_list[index] += '\n'
        if index > 0 and index % 12 == 0 and wrap_count < child_count - 1:
            wrap_count += 1
            wrap_name_list[index] += '\n'
    wrap_name = ''.join(wrap_name_list).strip()
    return wrap_name


def extract_notes(text=''):
    #     text = '''
    #         ****:tail -n 80 customSpec.json
    # <code>
    #
    # æ­¤å‘½ä»¤æ˜¾ç¤º Wasm äºŒè¿›åˆ¶å­—æ®µåé¢çš„æœ€åéƒ¨åˆ†ï¼Œ
    # åŒ…æ‹¬è¿è¡Œæ—¶ä½¿ç”¨çš„å‡ ä¸ªæ‰˜ç›˜çš„è¯¦ç»†ä¿¡æ¯ï¼Œ
    # ä¾‹å¦‚ sudo å’Œ balances æ‰˜ç›˜ã€‚
    # </code>;
    # ****:Modify the name field to identify this chain specification as a custom chain specification.
    # <code>
    #
    # "name": "My Custom Testnet",
    # </code>
    # ****:Modify aura field to specify the nodes
    # <code>
    #     '''
    # åŒæ—¶åŒ¹é…æ¢è¡Œç¬¦
    # (?:pattern) æ¥è§£å†³æ–¹æ‹¬å·ä¸é€‚ç”¨çš„åœºæ™¯
    # [æ­£åˆ™åŒ¹é…æ‰€æœ‰å­—ç¬¦ï¼ˆåŒ…æ‹¬æ¢è¡Œï¼‰_å°ä¸œä¸œçš„åšå®¢-CSDNåšå®¢_æ­£åˆ™åŒ¹é…æ‰€æœ‰å­—ç¬¦](https://blog.csdn.net/u011158908/article/details/105666329)
    notes = re.findall('\<code\>((?:.|\n)*?)\</code\>', text)
    return notes


def replace_process(raw_title: str):
    replace_list = [
        ('- ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦', '[ğŸ”—wiki]')
    ]
    for pre, after in replace_list:
        raw_title = raw_title.replace(pre, after)
    return raw_title


def extract_links(text=''):
    links = re.findall('\[\[(.*?)\]\]', text)
    link_list = []
    for link in links:
        href, title = link.split(' ', 1)
        if 'https://github.com' in href:
            url_title = '/'.join(href.split('/')[-2:])
            if ': ' in title:
                real_title, title_note = title.split(': ', 1)
            else:
                real_title, title_note = title, None
            link_dict = {
                'url_title': url_title,
                'link': href,
                'real_title': real_title,
                'raw_title': title,
                'title_note': title_note
            }
        else:
            # url_title = href.split('/')[-1]
            url_title = ''
            link_dict = {
                'url_title': url_title,
                'link': href,
                'real_title': title,
                'raw_title': title,
                'title_note': None
            }
        real_title = replace_process(title)
        link_dict['real_title'] = real_title
        link_list.append(link_dict)
    return link_list


# å¯¹æ ‡é¢˜å†…å®¹è¿›è¡Œé¢„å¤„ç†
def preprocess_title(puml_path: str):
    with open(puml_path, 'r') as f:
        lines = [line for line in f.readlines()]

    for index, line in enumerate(lines):
        links = extract_links(line)
        for link_detail in links:
            raw_title, url_title = link_detail['raw_title'], link_detail['url_title']
            if url_title and url_title != raw_title:
                lines[index] = lines[index].replace(raw_title, url_title)

    with open(puml_path, 'w') as f:
        f.writelines(lines)


if __name__ == "__main__":
    puml_dir = '../materials/anatomy/substrate'
    target_pumls = []
    for dirpath, dirnames, filenames in os.walk(puml_dir):
        print(dirpath, dirnames, filenames)
        for filename in filenames:
            target_pumls.append(f"{dirpath}/{filename}")
    mod = os.getenv('PUML_CONVERT_MOD')
    for puml_path in target_pumls:
        if mod == 'transform':
            if len(sys.argv) < 3:
                print("è¯·ä¼ å…¥pumlæ–‡ä»¶è·¯å¾„å’Œè½¬åŒ–ä¿å­˜è·¯å¾„")
                sys.exit()
            else:
                target_dir = sys.argv[2]
            converted_results = converter(puml_path)
            write_tree_json(converted_results, target_dir)
            # write_bubble_json(converted_results, target_dir)
            # write_knowledge_graph_json(converted_results, target_dir)
        elif mod == 'modify':
            preprocess_title(puml_path)
        else:
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡PUML_CONVERT_MOD")
